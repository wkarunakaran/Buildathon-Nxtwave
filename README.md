 KAN EZHUTHU AN AI Integrated Learning System for Visually & Hearing Impaired People with Braille and Sign Language

"Empowering Every Touch, Enabling Every Voice."

Kan Ezhuthu is an AI-integrated assistive learning system designed for both visually impaired and hearing-impaired students.
It simplifies education through:

ğŸ‘† Touch-based Braille learning
ğŸ™ï¸ Voice interaction
âœ‹ Sign Language recognition & animation
ğŸ¤– GenAI-powered content generation
ğŸ“š Personalized adaptive learning modules

This project bridges the education gap by providing affordable, interactive, and intelligent learning solutions in regional languages.

âœ¨ Key Features
ğŸ”µ Braille Learning Features
ğŸ“˜ Text â†’ Braille conversion (Tamil, English & regional languages)
ğŸ“ Braille â†’ Text conversion using OCR & AI
ğŸ§  AI-driven tailored learning modules
ğŸ§ª Dynamic test modes (adaptive difficulty)
ğŸ§ Voice-based navigation & explanations
ğŸ”Š AI-generated voice notifications
ğŸ”¡ Dynamic word generator based on user vocabulary
â“ Interactive Q/A for Braille doubts
ğŸŸ¢ Sign Language Features
âœ‹ Real-time sign detection using AI
ğŸ’¬ Sign â†’ Text + Speech output
ğŸ”„ Text â†’ 3D animated sign language avatar
ğŸ§ª Sign learning & tester mode
ğŸ“ˆ Performance scoring & gesture accuracy detection
 AI recommendations for next learning module
ğŸŸ£ Generative AI Features (Advanced)
ğŸ§  Context-aware sentence correction


ğŸ”„ AI-based translation (English â†” Tamil â†” regional)
âœï¸ GenAI story generator â†’ Braille output
â— AI-generated doubts clarifications
ğŸ“š AI-created quizzes, summaries, and practice modules
ğŸ¨ AI-assisted sign animation generation
ğŸ’¡ Adaptive learning recommendations
ğŸ« Why Kan Ezhuthu? (Motivation)


Millions of visually or hearing-impaired individuals struggle to learn due to:
âŒ Lack of accessible Braille content
âŒ High cost of assistive tools
âŒ Limited regional language support
âŒ No personalized learning
âŒ Minimal interactive tools
âŒ Dependency on teachers or caretakers


Kan Ezhuthu solves these using AI + hardware and offers a low-cost, scalable, inclusive education system.
ğŸ§© System Architecture
1. Input Layer
Voice
Text
Braille keypad
Camera (for sign detection)

2. Processing Layer
NLP + NLTK
OCR + Tesseract
Sign detection (MediaPipe/CNN)
GenAI (LLMs)
Reinforcement learning (adaptive tutor)

3. Output Layer
Braille hardware actuator
Voice output
Sign language animation
Text display


ğŸ§ª AI Workflows
ğŸ”¹ Braille AI Workflow
User input (voice/text/braille)
NLP + regional language processing
GenAI correction â†’ Braille mapping
Module selection based on performance
Dynamic test generation
Voice/Braille/visual output


ğŸ”¹ Sign Language AI Workflow
Camera captures gesture
AI extracts hand landmarks
Gesture classification
Text generation
Optional speech output
Feedback + accuracy score

ğŸ› ï¸ Tech Stack
Software
Python
Django / Flask
NLTK
GTTS / SpeechRecognition
TensorFlow / PyTorch
MediaPipe
Tesseract OCR
LLaMA / Mistral (optional GenAI)


ğŸ“ Project Structure
Kan-Ezhuthu/
â”‚
â”œâ”€â”€ braille_module/
â”œâ”€â”€ sign_module/
â”œâ”€â”€ ai_models/
â”œâ”€â”€ datasets/
â”œâ”€â”€ templates/
â”œâ”€â”€ static/
â”œâ”€â”€ hardware/
â”œâ”€â”€ main.py
â”œâ”€â”€ manage.py
â””â”€â”€ requirements.txt


ğŸ§ª Usage
Braille Learning
Convert text â†” Braille
Voice-guided learning
Adaptive module recommendations
Sign Learning
Real-time detection
Animated sign output
Test & practice modes
AI Learning
Ask questions
Generate explanations
Create assignments, summaries, stories




ğŸ§­ Future Enhancements
Portable Braille Printer
Coding language for visually impaired
Offline AI engine
AR/VR-based exposure therapy for learning
Regional sign language expansion
Cloud-based learning analytics

ğŸ¤ Team â€“ SHADOWS

TEAM LEAD - Wesley Karunakaran 
Team Members â€“ DHANUSH CHAKARAVARTHY, DHARSHINI C, BALAMANIKANDAN M
Mentor - Mrs. Uma Devi G


ğŸ“¬ Contact
ğŸ“§ wkarunakaran12b@gmail.com
ğŸ”— LinkedIn: https://www.linkedin.com/in/karunakaran-w
ğŸ™ GitHub: https://github.com/karunakaran7
